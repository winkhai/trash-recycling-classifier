{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Unzip the data and split it into train/val/test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the dataset is zipped, first we need to unzip using [zipfile library](https://docs.python.org/3/library/zipfile.html).\n",
    "\n",
    "We can use [tqdm library](https://tqdm.github.io/), which is awesome, to see the progress of the file as it's being unzipped. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2540/2540 [00:02<00:00, 1014.43it/s]\n"
     ]
    }
   ],
   "source": [
    "from zipfile import ZipFile\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Open the .zip file\n",
    "with ZipFile(file='dataset-resized.zip') as zip_file:\n",
    "\n",
    "    # Loop over each file\n",
    "    for file in tqdm(iterable=zip_file.namelist(), total=len(zip_file.namelist())):\n",
    "\n",
    "        # Extract the file to current working directory, no need to specify path\n",
    "        zip_file.extract(member=file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There are 6 classes (categories) of waste in this dataset:\n",
    "`cardboard`,`glass`,`metal`,`paper`,`plastic`,`trash`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***The dataset will be split into ~70-15-15% for train, valid, and test data.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***The following code is adapted from the [blog post](https://towardsdatascience.com/how-to-build-an-image-classifier-for-waste-sorting-6d11d3c9c478).***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## helper functions ##\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "## splits indices for a folder into train, validation, and test indices with random sampling\n",
    "    ## input: folder path\n",
    "    ## output: train, valid, and test indices    \n",
    "def split_indices(folder,seed1,seed2):    \n",
    "    n = len(os.listdir(folder))\n",
    "    full_set = list(range(1,n+1))\n",
    "\n",
    "    ## train indices\n",
    "    random.seed(seed1)\n",
    "    train = random.sample(list(range(1,n+1)),int(.7*n))\n",
    "\n",
    "    ## temp\n",
    "    remain = list(set(full_set)-set(train))\n",
    "\n",
    "    ## separate remaining into validation and test (15% for valid and another 15% for test)\n",
    "    random.seed(seed2)\n",
    "    valid = random.sample(remain,int(.5*len(remain)))\n",
    "    test = list(set(remain)-set(valid))\n",
    "    \n",
    "    return(train,valid,test)\n",
    "\n",
    "## gets file names for a particular type of trash, given indices\n",
    "    ## input: waste category and indices\n",
    "    ## output: file names \n",
    "def get_names(waste_type,indices):\n",
    "    file_names = [waste_type+str(i)+\".jpg\" for i in indices]\n",
    "    return(file_names)    \n",
    "\n",
    "## moves group of source files to another folder\n",
    "    ## input: list of source files and destination folder\n",
    "    ## no output\n",
    "def move_files(source_files,destination_folder):\n",
    "    for file in source_files:\n",
    "        shutil.move(file,destination_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## paths will be train/cardboard, train/glass, etc...\n",
    "data_split = ['train','valid','test']\n",
    "waste_classes = ['cardboard','glass','metal','paper','plastic','trash']\n",
    "\n",
    "## create destination folders for train, valid, test and each waste type\n",
    "for i in data_split:\n",
    "    for waste_class in waste_classes:\n",
    "        folder = os.path.join('data',i,waste_class)\n",
    "        #if os.path.exists(folder):\n",
    "          #print(f'folder {folder} already exists.')\n",
    "          #return\n",
    "        if not os.path.exists(folder):\n",
    "            os.makedirs(folder)\n",
    "            \n",
    "if not os.path.exists(os.path.join('data','test')):\n",
    "    os.makedirs(os.path.join('data','test'))\n",
    "            \n",
    "## move files to destination folders for each waste class\n",
    "for waste_class in waste_classes:\n",
    "    source_folder = os.path.join('dataset-resized',waste_class)\n",
    "    train_ind, valid_ind, test_ind = split_indices(source_folder,1,1)\n",
    "    \n",
    "    ## move source files to train\n",
    "    train_names = get_names(waste_class,train_ind)\n",
    "    train_source_files = [os.path.join(source_folder,name) for name in train_names]\n",
    "    train_dest = \"data/train/\" + waste_class\n",
    "    move_files(train_source_files,train_dest)\n",
    "    \n",
    "    ## move source files to valid\n",
    "    valid_names = get_names(waste_class,valid_ind)\n",
    "    valid_source_files = [os.path.join(source_folder,name) for name in valid_names]\n",
    "    valid_dest = \"data/valid/\" + waste_class\n",
    "    move_files(valid_source_files,valid_dest)\n",
    "    \n",
    "    ## move source files to test\n",
    "    test_names = get_names(waste_class,test_ind)\n",
    "    test_source_files = [os.path.join(source_folder,name) for name in test_names]\n",
    "    test_dest = \"data/test/\" + waste_class\n",
    "    move_files(test_source_files,test_dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
